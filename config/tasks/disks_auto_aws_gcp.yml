---

- name: disks_auto_aws_gcp | cluster_hosts_target(inventory_hostname)
  debug: msg={{ cluster_hosts_target | json_query(\"[?hostname == '\" + inventory_hostname + \"'] \") }}

- name: disks_auto_aws_gcp | Mount block devices as individual disks
  block:
    - name: disks_auto_aws_gcp | auto_vols
      debug: msg={{ auto_vols }}

    - name: disks_auto_aws_gcp | Get the block device information (pre-filesystem create)
      blockdevmap:
        cloud_type: "{{cluster_vars.type}}"
      become: yes
      register: r__blockdevmap

    - name: disks_auto_aws_gcp | r__blockdevmap (pre-filesystem create)
      debug: msg={{r__blockdevmap}}

    - name: disks_auto_aws_gcp | Create filesystem (partitionless)
      become: yes
      filesystem:
        fstype: "{{ item.fstype }}"
        dev: "{{ _dev }}"
      loop: "{{auto_vols}}"
      vars:
        _dev: "{{ r__blockdevmap.device_map | json_query(\"[?device_name_cloud == '\" + item.device_name + \"' && TYPE=='disk' && parttable_type=='' && FSTYPE=='' && MOUNTPOINT==''].device_name_os | [0]\") }}"
      when: _dev is defined and _dev != ''

    - name: disks_auto_aws_gcp | Get the block device information (post-filesystem create), to get the block IDs for mounting
      blockdevmap:
        cloud_type: "{{cluster_vars.type}}"
      become: yes
      register: r__blockdevmap

    - name: disks_auto_aws_gcp | r__blockdevmap (post-filesystem create)
      debug: msg={{r__blockdevmap}}

    - name: disks_auto_aws_gcp | Mount created filesytem(s) persistently
      become: yes
      mount:
        path: "{{ item.mountpoint }}"
        src: "UUID={{ _UUID }}"
        fstype: "{{ item.fstype }}"
        state: mounted
        opts: _netdev
      loop: "{{auto_vols}}"
      vars:
        _UUID: "{{ r__blockdevmap.device_map | json_query(\"[?device_name_cloud == '\" + item.device_name + \"' && TYPE=='disk' && parttable_type=='' && MOUNTPOINT==''].UUID | [0]\") }}"
      when: _UUID is defined and _UUID != ''

    - name: disks_auto_aws_gcp | change ownership of mountpoint (if set)
      become: yes
      file:
        path: "{{ item.mountpoint }}"
        state: directory
        mode: "{{ item.perms.mode | default(omit)}}"
        owner: "{{ item.perms.owner | default(omit)}}"
        group: "{{ item.perms.group | default(omit)}}"
      loop: "{{auto_vols}}"

    - name: disks_auto_aws_gcp | Check that we haven't mounted disks in the wrong place.  Especially useful for redeploys when we're moving disks.
      block:
        - name: "disks_auto_aws_gcp | Touch a file with the mountpoint and device name for testing that disk attachment is correct.  Note: Use a unique filename here instead of writing to a file, so that more than one file per device is an error."
          become: yes
          file:
            path: "{{item.mountpoint}}/.clusterversetest__{{inventory_hostname | regex_replace('-(?!.*-).*')}}__{{ item.mountpoint | regex_replace('\\/', '_') }}__{{ item.device_name | regex_replace('\/', '_') }}"
            state: touch
          loop: "{{auto_vols}}"

        - name: disks_auto_aws_gcp | Find all .clusterversetest__ files in mounted disks
          find:
            paths: "{{item.mountpoint}}"
            hidden: yes
            patterns: ".clusterversetest__*"
          loop: "{{auto_vols}}"
          register: r__find_test

        - name: disks_auto_aws_gcp | Check that there is only one .clusterversetest__ file per device in mounted disks.
          block:
            - name: disks_auto_aws_gcp | testdevicedescriptor
              debug: msg={{testdevicedescriptor}}

            - name: disks_auto_aws_gcp | assert that only one device descriptor file exists per disk (otherwise, indicates that this run has mapped either more than one device per mount, or a different one to previous)
              assert: { that: "testdevicedescriptor | json_query(\"[?length(files) > `1`]\") | length == 0", fail_msg: "ERROR - Exactly one file should exist per storage device.  In error [{{testdevicedescriptor | json_query(\"[?length(files) > `1`]\")}}]" }
          vars:
            testdevicedescriptor: "{{ r__find_test | json_query(\"results[].{hostname: '\" + inventory_hostname + \"', device_name: item.device_name, mountpoint: item.mountpoint, files: files[].path}\") }}"
      when: test_touch_disks is defined and test_touch_disks|bool
  when: (auto_vols | map(attribute='mountpoint') | list | unique | count == auto_vols | map(attribute='mountpoint') | list | count)
  vars:
    auto_vols: "{{ cluster_hosts_target | json_query(\"[?hostname == '\" + inventory_hostname + \"'].auto_volumes[]\") }}"


# The following block mounts all attached volumes that have a single, common mountpoint, by creating a logical volume
- name: disks_auto_aws_gcp/lvm | Mount block devices in a single LVM mountpoint through LV/VG
  block:
    - name: disks_auto_aws_gcp/lvm | hosttype_vars
      debug: msg={{ hosttype_vars }}

    - name: disks_auto_aws_gcp/lvm | Install logical volume management tooling. (yum - RedHat/CentOS)
      become: true
      yum:
        name: "lvm*"
        state: present
      when: ansible_os_family == 'RedHat'

    - name: disks_auto_aws_gcp/lvm | Get the device information (pre-filesystem create)
      blockdevmap:
        cloud_type: "{{cluster_vars.type}}"
      become: yes
      register: r__blockdevmap

    - name: disks_auto_aws_gcp/lvm | r__blockdevmap (pre-filesystem create)
      debug: msg={{r__blockdevmap}}

    - name: disks_auto_aws_gcp/lvm | Create a volume group from all block devices
      become: yes
      lvg:
        vg:  "{{ lvmparams.vg_name }}"
        pvs: "{{ r__blockdevmap.device_map | json_query(\"[?device_name_cloud && contains('\" + auto_vol_device_names + \"', device_name_cloud)].device_name_os\") | join(',')}}"
      vars:
        auto_vol_device_names: "{{hosttype_vars.auto_volumes | map(attribute='device_name') | sort  | join(',')}}"

    - name: disks_auto_aws_gcp/lvm | Create a logical volume from volume group
      become: yes
      lvol:
        vg: "{{ lvmparams.vg_name }}"
        lv: "{{ lvmparams.lv_name }}"
        size: "{{ lvmparams.lv_size }}"

    - name: disks_auto_aws_gcp/lvm | Create filesystem(s) on attached volume(s)
      become: yes
      filesystem:
        fstype: "{{ hosttype_vars.auto_volumes[0].fstype }}"
        dev: "/dev/{{ lvmparams.vg_name }}/{{ lvmparams.lv_name }}"
        force: no

    - name: disks_auto_aws_gcp/lvm | Mount created filesytem(s) persistently
      become: yes
      mount:
        path: "{{ hosttype_vars.auto_volumes[0].mountpoint }}"
        src: "/dev/{{ lvmparams.vg_name }}/{{ lvmparams.lv_name }}"
        fstype: "{{ hosttype_vars.auto_volumes[0].fstype }}"
        state: mounted
        opts: _netdev

    - name: disks_auto_aws_gcp/lvm | Check that we haven't mounted disks in the wrong place.  Especially useful for redeploys when we're moving disks.
      block:
        - name: "disks_auto_aws_gcp/lvm | Touch a file with the mountpoint for testing that disk attachment is correct.  Note: Use a unique filename here instead of writing to a file, so that more than one file per device is an error."
          become: yes
          file:
            path: "{{ hosttype_vars.auto_volumes[0].mountpoint }}/.clusterversetest__{{inventory_hostname | regex_replace('-(?!.*-).*')}}__{{ hosttype_vars.auto_volumes[0].mountpoint | regex_replace('\\/', '_') }}"
            state: touch

        - name: disks_auto_aws_gcp/lvm | Find all .clusterversetest__ files in mounted disks
          find:
            paths: "{{ hosttype_vars.auto_volumes[0].mountpoint }}"
            hidden: yes
            patterns: ".clusterversetest__*"
          register: r__find_test

        - debug: msg={{r__find_test}}

        - name: disks_auto_aws_gcp/lvm | assert that only one device descriptor file exists per disk (otherwise, indicates that this run has mapped either more than one device per mount, or a different one to previous)
          assert: { that: "'files' in r__find_test != ''  and  r__find_test.files | length == 1", fail_msg: "ERROR - Exactly one file should exist per LVM." }
      when: test_touch_disks is defined and test_touch_disks|bool
  when: (lvmparams is defined and lvmparams != '')  and  (hosttype_vars.auto_volumes | selectattr('mountpoint', '!=', '/') | map(attribute='mountpoint') | list | unique | count == 1) and (hosttype_vars.auto_volumes | selectattr('mountpoint', '!=', '/') | map(attribute='mountpoint') | list | count >= 2) and (hosttype_vars.auto_volumes | map(attribute='fstype') | list | unique | count == 1)
  vars:
    hosttype_vars: "{{ cluster_hosts_target | json_query(\"[?hostname == '\" + inventory_hostname + \"'] | [0]\") }}"
    lvmparams: "{{ cluster_vars[buildenv].hosttype_vars[hosttype_vars.hosttype].lvmparams | default('') }}"
