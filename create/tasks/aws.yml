---

- name: Create AWS security group
  ec2_group:
    name: "{{ cluster_name }}-sg"
    description: "{{ cluster_name }} rules"
    region: "{{cluster_vars.region}}"
    vpc_id: "{{vpc_id}}"
    aws_access_key: "{{cluster_vars[buildenv].aws_access_key}}"
    aws_secret_key: "{{cluster_vars[buildenv].aws_secret_key}}"
    tags:
      Name: "{{ cluster_name }}-sg"
      env: "{{ buildenv }}"
    rules: "{{ cluster_vars.secgroup_new }}"
    rules_egress:
      - proto: all
        cidr_ip: 0.0.0.0/0
  register: new_aws_sg
  when: cluster_vars.secgroup_new | length > 0

- name: Create EC2 instances
  block:
    - name: Create EC2 instances
      ec2:
        aws_access_key: "{{cluster_vars[buildenv].aws_access_key}}"
        aws_secret_key: "{{cluster_vars[buildenv].aws_secret_key}}"
        region: "{{cluster_vars.region}}"
        key_name: "{{cluster_vars[buildenv].key_name}}"
        instance_type: "{{item.flavor}}"
        instance_profile_name: "{{cluster_vars.instance_profile_name  | default(omit)}}"
        image: "{{cluster_vars.image}}"
        vpc_subnet_id: "{{item.vpc_subnet_id}}"
        assign_public_ip: "{{cluster_vars.assign_public_ip}}"
        group: "{{ cluster_vars.secgroups_existing }} {%- if cluster_vars.secgroup_new | length > 0 -%} + {{ ([new_aws_sg.group_name | default()] | default())}} {%- endif -%}"
        wait: yes
        instance_tags:
          Name: "{{item.hostname}}"
          hosttype: "{{item.hosttype}}"
          env: "{{buildenv}}"
          release: "{%- if rescuing is defined and rescuing != \"false\" and instance_to_create is defined and instance_to_create == item.hostname -%}{{rescuing}}{%- elif instance_to_create is defined and instance_to_create == item.hostname -%}{{item.release}}{%- else -%}{{item.current_release}}{%- endif -%}"
          deploy_status: "{%- if rescuing is defined and rescuing != \"false\" and instance_to_create is defined and instance_to_create == item.hostname -%}old{%- elif instance_to_create is defined and instance_to_create == item.hostname -%}new{%- else -%}{{item.current_deploy_status}}{%- endif -%}"
          cluster_name: "{{cluster_name}}"
          owner: "{{ lookup('env','USER')| lower }}"
          maintenance_mode: "{%- if prometheus_set_unset_maintenance_mode|bool -%}true{%- else -%}false{%- endif -%}"
        termination_protection: "{{cluster_vars[buildenv].termination_protection}}"
        volumes: "{{ item.auto_volumes | default([]) }}"
        count_tag:
          Name: "{{item.hostname}}"
        exact_count: 1
      with_items: "{{cluster_hosts_flat}}"
      async: 7200
      poll: 0
      register: aws_instances

    - name: Wait for aws instance creation to complete
      async_status:
        jid: "{{ item.ansible_job_id }}"
      register: aws_jobs
      until: aws_jobs.finished
      delay: 3
      retries: 300
      with_items: "{{aws_instances.results}}"

  #    - debug: msg={{aws_jobs.results}}

    - name: set a fact containing newly-created hosts
      set_fact:
        cluster_hosts_flat_created: "{{ aws_jobs.results | json_query(\"[?changed==`true`].item.item\") }}"
      delegate_to: localhost
      run_once: true

    - name: update release tag when run normal deploy
      ec2_tag:
        aws_access_key: "{{cluster_vars[buildenv].aws_access_key}}"
        aws_secret_key: "{{cluster_vars[buildenv].aws_secret_key}}"
        region: "{{cluster_vars.region}}"
        resource: "{{ item }}"
        tags:
          release: "{{ release_version }}"
      delegate_to: localhost
      run_once: true
      with_items: "{{ aws_jobs.results | json_query('[].tagged_instances[0].id')}}"
      when: (instance_to_create is undefined and rescuing is undefined)

    - name: force set maintenance_mode to true (when prometheus_set_unset_maintenance_mode)
      ec2_tag:
        aws_access_key: "{{cluster_vars[buildenv].aws_access_key}}"
        aws_secret_key: "{{cluster_vars[buildenv].aws_secret_key}}"
        region: "{{cluster_vars.region}}"
        resource: "{{ item }}"
        tags:
          maintenance_mode: "true"
      delegate_to: localhost
      run_once: true
      with_items: "{{ aws_jobs.results | json_query('[].tagged_instances[0].id')}}"
      when: (prometheus_set_unset_maintenance_mode is defined and prometheus_set_unset_maintenance_mode|bool)

    - name: Extract EBS volume data so we can tag the disks
      set_fact:
        ebsdata: |
          {% set res = [] -%}
          {%- for host in aws_jobs.results -%}
            {%- for devkey in host.tagged_instances[0].block_device_mapping.keys()-%}
            {% set _dummy = res.extend([{
              'hostname': host.tagged_instances[0].tags.Name,
              'ec2_id': host.tagged_instances[0].id,
              'device_name': devkey,
              'volume_id': host.tagged_instances[0].block_device_mapping[devkey].volume_id
              }]) -%}
            {%- endfor %}
          {%- endfor %}
          {{ res }}

#    - debug: msg={{ebsdata}}

    - name: set the ec2 volume name tag
      ec2_tag:
        aws_access_key: "{{cluster_vars[buildenv].aws_access_key}}"
        aws_secret_key: "{{cluster_vars[buildenv].aws_secret_key}}"
        region: "{{cluster_vars.region}}"
        resource: "{{item.volume_id}}"
        tags:
          Name: "{{ item.hostname }}--{{item.device_name | regex_replace('^.*\\/(.*)', '\\1')}}"
      with_items: "{{ebsdata}}"
